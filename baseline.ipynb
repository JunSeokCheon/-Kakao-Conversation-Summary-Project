{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import re\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from eval import get_eval_data, pointwise_eval\n",
    "from utils import summarize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "비용 기반 후보 모델 선정\n",
    "- Claude 3 Haiku\n",
    "- Gemini 1.5 flash\n",
    "- ChatGPT 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_BASELINE = f\"\"\"아래 사용자 대화에 대해 3문장 내로 요약해주세요:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'P01: 오빠도 드뎌 우리 엄빠한테도 소개도 하고 인정도 받은것 같아서\\nP01: 매우 좋다\\nP02: 나도 뭔가\\nP01: 다행이양\\nP02: 마음이 좀 편안하긴하네\\nP01: 응응\\nP01: 전에 오빠가 나한테\\nP01: 오빠네 어머니가 나 예뻐하시는것 처럼\\nP01: 자기도 그런것 받고 싶다\\nP01: 라는 식으로 얘기를 했었는데\\nP01: 좀 되게\\nP01: 마음이 아프더라고\\nP02: 비수를\\nP02: 꽂았네\\nP01: 아흉\\nP01: 마음에서 눈물이난다\\nP01: 그래서\\nP01: 나도 계속 엄빠한테\\nP01: 오빠가 이렇게 섬세한 사람이야~\\nP01: 이것까지 생각해서\\nP01: 엄빠 챙겨드린거야~\\nP01: 이러면서\\nP01: 오빠 예뻐해달라고 막 어필하고\\nP01: 돌려서\\nP01: 또 엄빠도 내 이런 마음아니까 또\\nP01: 그럴때마다 좋게 봐주려고도 하고\\nP01: 그러시더라\\nP02: #@이름#이\\nP02: 감격스럽나보넹\\nP01: 그렇지머'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_eval_data()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 대화에서 P01은 자신의 오빠가 부모님께 소개되어 인정받은 것에 대해 기쁨을 표현하고, 오빠가 자신의 부모님께 인정받고 싶어 했던 것을 기억하며 부모님께 오빠를 잘 보이려 노력했다. P02는 P01의 감정을 이해하고 공감하는 모습을 보인다.\n",
      "The AI assistant's response provides a clear and accurate summary of the conversation between P01 and P02. It captures the main points of the dialogue, including P01's efforts to have her brother recognized by their parents and P02's empathetic response. The summary is relevant and helpful, as it encapsulates the essence of the conversation without adding unnecessary details.\n",
      "\n",
      "Rating: [[9]]\n"
     ]
    }
   ],
   "source": [
    "summary = summarize(\n",
    "    conversation=get_eval_data()[0],\n",
    "    prompt=PROMPT_BASELINE,\n",
    "    model='claude-3-haiku-20240307'\n",
    ")\n",
    "\n",
    "eval_comment = pointwise_eval(get_eval_data()[0], summary)\n",
    "\n",
    "print(summary)\n",
    "print(eval_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P01은 남자친구가 P01의 부모님께 인정받게 되어 기쁘고, 이전에 남자친구가 자신의 부모님으로부터 받고 싶어했던 사랑을 자신도 부모님께 받게 해드리고 싶어 노력했다고 말합니다.  P02는 P01의 마음이 편안해 보인다고 공감하며,  P01의 노력에 감격스러워하는 모습을 보입니다.  결국, 두 사람은 서로의 부모님으로부터의 인정과 사랑에 대한 이야기를 나누며 감정을 공유합니다.\n",
      "\n",
      "The AI assistant's response provides a clear and accurate summary of the conversation between P01 and P02. It captures the main points, such as P01's happiness about her boyfriend being accepted by her parents, her efforts to make her parents appreciate him, and P02's empathetic response. The summary is relevant and helpful, as it encapsulates the essence of the conversation without adding unnecessary details.\n",
      "\n",
      "Rating: [[9]]\n"
     ]
    }
   ],
   "source": [
    "summary = summarize(\n",
    "    conversation=get_eval_data()[0],\n",
    "    prompt=PROMPT_BASELINE,\n",
    "    model='gemini-1.5-flash'\n",
    ")\n",
    "\n",
    "eval_comment = pointwise_eval(get_eval_data()[0], summary)\n",
    "\n",
    "print(summary)\n",
    "print(eval_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P01이 엄빠에게 소개를 받고 인정을 받아 기뻐하고, P02는 마음이 편안해진다고 한다. P01은 오빠와의 대화에서 마음이 아프다고 했고, P02는 비수를 꽂았다는 표현을 사용한다. P01은 엄빠에게 어필하며 엄빠의 섬세함을 칭찬하고, P02는 감격스러워한다.\n",
      "The AI assistant's response is a summary of the conversation, but it lacks depth and does not provide any additional insights or helpful information. It merely restates what was already said without adding value or addressing any potential questions or concerns the user might have had. The response is relevant but not particularly helpful or engaging.\n",
      "\n",
      "Rating: [[4]]\n"
     ]
    }
   ],
   "source": [
    "summary = summarize(\n",
    "    conversation=get_eval_data()[0],\n",
    "    prompt=PROMPT_BASELINE,\n",
    "    model='gpt-3.5-turbo-0125'\n",
    ")\n",
    "\n",
    "eval_comment = pointwise_eval(get_eval_data()[0], summary)\n",
    "\n",
    "print(summary)\n",
    "print(eval_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cc9c044fa454315b60fb726b364e014",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "503f8e7e6efe48519ecdcc8c1a01e8f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fcde1ddf1264468a9c6e6952a510c08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = [\n",
    "    'claude-3-haiku-20240307',\n",
    "    'gemini-1.5-flash-001',\n",
    "    'gpt-3.5-turbo-0125'\n",
    "]\n",
    "scores = {model: [] for model in models}\n",
    "pattern = r'\\[\\[\\d+\\]\\]'\n",
    "\n",
    "for model in models:\n",
    "    for i in tqdm(range(len(get_eval_data()))):\n",
    "        summary = summarize(\n",
    "            conversation=get_eval_data()[i],\n",
    "            prompt=PROMPT_BASELINE,\n",
    "            model=model\n",
    "        )\n",
    "        eval_comment = pointwise_eval(get_eval_data()[i], summary)\n",
    "        # 점수(score) 파싱 부분\n",
    "        match = re.search(pattern, eval_comment)\n",
    "        matched_string = match.group(0)\n",
    "        score = int(matched_string[2])\n",
    "        scores[model].append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 7, 6, 6, 5, 6, 4, 6, 6, 7, 8, 7, 6, 6, 6, 7, 7, 6, 6, 7, 4, 7, 7, 8, 7, 7, 6, 5, 6, 4, 7, 8, 7, 6, 8, 7, 6, 6, 6, 6] claude-3-haiku-20240307\n",
      "[9, 8, 8, 8, 5, 7, 6, 8, 7, 8, 7, 4, 6, 5, 7, 6, 5, 8, 8, 8, 6, 7, 6, 9, 9, 8, 8, 6, 7, 6, 8, 8, 8, 8, 7, 8, 5, 7, 6, 7] gemini-1.5-flash-001\n",
      "[4, 6, 5, 7, 3, 4, 4, 3, 4, 5, 4, 8, 5, 4, 7, 5, 7, 6, 5, 6, 6, 5, 6, 6, 9, 4, 6, 6, 6, 3, 4, 6, 4, 5, 8, 7, 4, 5, 5, 4] gpt-3.5-turbo-0125\n"
     ]
    }
   ],
   "source": [
    "# 전체 점수 출력\n",
    "for model in scores:\n",
    "    print(scores[model], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "claude-3-haiku-20240307: 6.35 / 1.0\n",
      "gemini-1.5-flash-001: 7.05 / 1.24\n",
      "gpt-3.5-turbo-0125: 5.275 / 1.43\n"
     ]
    }
   ],
   "source": [
    "# 평균 점수 계산 / 표준 편차\n",
    "for model in scores:\n",
    "    mean = sum(scores[model]) / len(scores[model])\n",
    "    variance = sum((x - mean) ** 2 for x in scores[model]) / (len(scores[model]) - 1)\n",
    "    std_dev = math.sqrt(variance)\n",
    "    print(f'{model}: {mean} / {round(std_dev, 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "claude-3-haiku-20240307 8 4\n",
      "gemini-1.5-flash-001 9 4\n",
      "gpt-3.5-turbo-0125 9 3\n"
     ]
    }
   ],
   "source": [
    "# 최대 / 최소 점수수\n",
    "for model in scores:\n",
    "    print(model, max(scores[model]), min(scores[model]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kakao-summary",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
